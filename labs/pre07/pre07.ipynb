{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae75c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"pre07.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97ad69d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "# Lab 7: Great British Bake Off (A/B Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bfe4d0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Helpful Resources:**\n",
    "- [Python Reference](http://www.cs.williams.edu/~cs104/python-library-ref.html): Cheat sheet of helpful library methods.\n",
    "\n",
    "**Readings:**\n",
    "* [Ch 12.1. A/B Testing](https://inferentialthinking.com/chapters/12/1/AB_Testing.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5277241",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the following cell to setup the notebook by importing some helpful libraries. Each time you start your server, you will need to execute this cell again.  For all problems that you must write explanations and sentences for, you **must** provide your answer in the designated space. **Moreover, throughout this prelab and all future ones, please be sure to not re-assign variables throughout the notebook!** For example, if you use `max_temperature` in your answer to one question, do not reassign it later on. Otherwise, you will fail tests that you thought you were passing previously!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228b799",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "\n",
    "# These lines import the Numpy and Datascience modules.\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines make plots look nice and hide some messy Python warnings.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "warnings.simplefilter('ignore', np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516338e2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1. A/B Testing (10 pts)\n",
    "\n",
    "\n",
    "A/B testing is a form of hypothesis testing that allows you to make comparisons between two distributions. We may also refer to an A/B test as a permutation test.\n",
    "\n",
    "You'll almost never be explicitly asked to perform an A/B test. Make sure you can identify situations where the test is appropriate and know how to correctly implement each step. Oftentimes, we use an A/B test to determine whether or not two samples came from the same underlying distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3052522",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Part 1.1 (5 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fae25e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    " The following statements are the steps of an A/B hypothesis test presented in a *random order*:\n",
    "\n",
    "1. Choose a test statistic (typically the difference in means between two categories)\n",
    "\n",
    "2. Shuffle the labels of the original sample, find your simulated test statistic, and repeat many times\n",
    "\n",
    "3. Find the value of the observed test statistic\n",
    "\n",
    "4. Calculate the p-value based off your observed and simulated test statistics\n",
    "\n",
    "5. Define a null and alternate model\n",
    "\n",
    "6. Use the p-value and p-value cutoff to draw a conclusion about the null hypothesis\n",
    "\n",
    "Assign `ab_test_order` to an array of integers that contains the correct order of an A/B test, where the first item of the array is the first step of an A/B test and the last item of the array is the last step of an A/B test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28bc67f",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ab_test_order = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0074c87f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c52ec53",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Part 1.2 (5 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c727ac5d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Which of the following two statements is correct.  Assign your answer to `null_hyp_answer` below:\n",
    "\n",
    "1. If the null hypothesis of an A/B test is correct, the order of labels affects the differences in means between each group.\n",
    "2. If the null hypothesis of an A/B test is correct, the order of labels does not affect the differences in means between each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79852e7",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "null_hyp_answer = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a65f9c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80bc0ac",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 2. The Great British Bake Off (40 pts)\n",
    "\n",
    "\n",
    ">\"The Great British Bake Off (often abbreviated to Bake Off or GBBO) is a British television baking competition, produced by Love Productions, in which a group of amateur bakers compete against each other in a series of rounds, attempting to impress a group of judges with their baking skills\" [Wikipedia](https://en.wikipedia.org/wiki/The_Great_British_Bake_Off)\n",
    "\n",
    "For every week of the competition, the judges assign one contestant the title \"Star Baker\". Ultimately, one winner is crowned every season. Using this information, we would like to investigate how winning Star Baker awards affects the odds of winning a season of the show.   Answering that question requires more than just comparing star baker award rates for season winners and losers because, without a randomized controlled experiment, we may be misled by confounding factors or reverse causation.  This leads us to..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd0146",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Running an Experiment\n",
    "\n",
    "We are going to run the following hypothesis test to determine the association between winning and number of Star Baker awards. The population we are examining is every contestant from seasons 2 through 11 of GBBO. We are going to use the following null and alternative hypotheses:\n",
    "\n",
    "**Null hypothesis:** The distribution of Star Baker awards between contestants who won their season and contestants who did not win their season is the same.\n",
    "\n",
    "**Alternative hypothesis:** Contestants who win their season of the show will win more Star Baker awards on average.\n",
    "\n",
    "Our alternative hypothesis is related to our suspicion that contestants who win more Star Baker awards are more skilled, so they are more likely to win the season."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f55586",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The `bakers` table below describes the number of star baker awards each contest won and whether or not they won their season (`1` if they won, `0` if they did not win). The data was manually aggregated from Wikipedia for seasons 2-11 of the show. We randomized the order of rows as to not spoil the outcome of the show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89ab054",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "bakers = Table.read_table(\"star_bakers.csv\")\n",
    "bakers.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d90548a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Part 2.1 (5 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7770ea",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    " Create a new table called `means` that contains the mean number of star baker awards for bakers who did not win (`won==0`) and bakers that did win (`won==1`). The table should have the column names `won` and `star baker awards mean`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42097447",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "means = ...\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e8c27",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8702b834",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Part 2.2 (5 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a18c02",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Using the original `bakers` table, visualize the distribution of Star Baker awards for winners and non-winners. You should use the bins we provided.\n",
    "\n",
    "Hint: You will want to use the group argument of `tbl.hist`. In order to produce several overlayed histograms based on unique values in a given column, we can do something like `tbl.hist(..., group=<col_name>, bins=...)`!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65087b0e",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "useful_bins = np.arange(0, 7)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f3f667",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Part 2.3 (5 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac4d62",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We want to figure out if there is a difference between the awarding of Star Baker awards between winners and non winners. We can use as the test statistic the difference of means between our two groups.  Differences close to 0 support the null hypothesis -- that there is no distinction between winners and non winners.  Large differences support the alternative hypothesis that there is a distinction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9578372b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "#### Part 2.4 (5 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1bd672",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    " Set `observed_difference` to the observed test statistic using the `means` table. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c489e8",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "observed_difference = ...\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1167765e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2494e7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Part 2.5 (5 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ed5f4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We'll now generalize the computation you did above.  Given a table like `bakers`, a value column `label_col`, and a group column `group_col`, write a function that calculates the appropriate test statistic.\n",
    "\n",
    "*Hint:* Make sure that you are taking the directionality of our alternative hypothesis into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6632212",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_test_stat(table, group_col, values_col):\n",
    "    \"\"\"Takes: the table, the column indicating which of two groups\n",
    "    each row belongs, and the column containing the values.\n",
    "    Returns: Difference of the means of the two groups.\"\"\"\n",
    "    means_table = table.group(group_col, np.mean)\n",
    "    means = ...\n",
    "    return means.item(1) - means.item(0)\n",
    "\n",
    "find_test_stat(bakers, \"won\", \"star baker awards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffeace4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0fe156",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "When we run a simulation for A/B testing, we resample by **shuffling the labels** of the original sample. If the null hypothesis is true and the star baker award distributions are the same, we expect that the difference in mean star baker awards will be not change when `\"won\"` labels are changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66070c25",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Part 2.6 (5 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd0594",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    " Write a function `simulate_and_test_statistic` to compute one trial of our A/B test. Your function should run a simulation and return a test statistic.  The first step is to create a new version of the given `table` table in which the `labels_col` column is shuffled.  Recall that, given a table `table`, you can obtain a shuffled version of a column via `table.sample(with_replacement=False).column(labels_col)`.  The second step is to use your `find_test_stat` function to compute the test statistic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71469eaa",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_and_test_statistic(table, labels_col, values_col):\n",
    "    shuffled_labels = ...\n",
    "    shuffled_table = ...\n",
    "    ...\n",
    "\n",
    "simulate_and_test_statistic(bakers, \"won\", \"star baker awards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892c289",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb1daa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Part 2.7 (5 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3815638",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    " Simulate 5000 trials of our A/B test and store the test statistics in an array called `differences`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa6fca",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell might take a couple seconds to run\n",
    "differences = make_array()\n",
    "\n",
    "repetitions = 5000\n",
    "for i in np.arange(repetitions):\n",
    "    new_difference = ...\n",
    "    differences = np.append(differences, new_difference)                               \n",
    "                                                 \n",
    "differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a850be37",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c083b9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Run the cell below to view a histogram of your simulated test statistics plotted with your observed test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f855a4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "Table().with_column('Difference Between Group Means', differences).hist(bins=20)\n",
    "plots.scatter(observed_difference, 0, color='red', s=30, zorder=2)\n",
    "plots.ylim(-0.1, 1.35);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66baf586",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Part 2.8 (5 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683df60a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Find the p-value for your test and assign it to `empirical_p`.  In this case, small differences in the means support the null hypothesis.  So, to computer the p-value, we'll need to count the number of values in our `differences` distribution that are **larger** than our `observed_difference`.  The p-value is the number of such values in `differences` divided by `repetitions`, the size of `differences`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4864e5e",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "empirical_p = np.count_nonzero(...) / ...\n",
    "\n",
    "empirical_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27dba59",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db433784",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Part 2.9 (5 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e3b407",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Using a 5% P-value cutoff, draw a conclusion about the null and alternative hypotheses.  Store in the `conclusion` variable which of the following two conclusions is supported by your analysis:\n",
    "\n",
    "1. Winning star baker awards does not increase to being the season winner.\n",
    "2. Winning star baker awards increases the likelihood of being the season winner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45a9e62",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "conclusion = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea64bf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49ccbf9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## 3. You're Done!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ef0ba5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Important submission information:** Follow these steps to submit your work:\n",
    "* Run the tests and verify that they pass as you expect. \n",
    "* Choose **Save Notebook** from the **File** menu.\n",
    "* **Run the final cell** and click the link below to download the zip file. \n",
    "\n",
    "Once you have downloaded that file, go to [Gradescope](https://www.gradescope.com/) and submit the zip file to the corresponding assignment. The name of this assignment is \"Prelab 7 Autograder\". **Be sure your work is saved before running the last cell!**\n",
    "\n",
    "Once you have submitted, your Gradescope assignment should show you passing all the tests you passed in your assignment notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa624040",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc0d3a1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317156e0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4db4c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7619a00",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "otter": {
   "tests": {
    "q1.1": {
     "name": "q1.1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(ab_test_order) == 6\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> correct_order = make_array(5, 1, 3, 2, 4, 6)\n>>> all(correct_order == ab_test_order)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.2": {
     "name": "q1.2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> null_hyp_answer == 2\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.1": {
     "name": "q2.1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(means.where(\"won\", 0).row(0).item(\"star baker awards mean\"), 0.65179)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(means.where(\"won\", 1).row(0).item(\"star baker awards mean\"), 1.5)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.3": {
     "name": "q2.3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> round(observed_difference, 5) == 0.84821\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.5": {
     "name": "q2.5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> round(find_test_stat(bakers, \"won\", \"star baker awards\"), 5) == 0.84821\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.6": {
     "name": "q2.6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> -5 <= simulate_and_test_statistic(bakers, \"won\", \"star baker awards\") <= 5\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.7": {
     "name": "q2.7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.all(-5 <= differences) and np.all(differences <= 5)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.8": {
     "name": "q2.8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 <= empirical_p <= 0.05\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.9": {
     "name": "q2.9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> conclusion == 2\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
